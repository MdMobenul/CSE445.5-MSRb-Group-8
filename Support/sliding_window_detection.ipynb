{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Sign Detection using Sliding Window Algorithm\n",
    "\n",
    "This notebook implements a sliding window algorithm to detect stop signs in images. The algorithm:\n",
    "1. Slides a window of fixed size across the image at multiple scales\n",
    "2. Extracts HOG features from each window\n",
    "3. Classifies each window using a trained SVM model\n",
    "4. Applies non-maximum suppression to remove overlapping detections\n",
    "5. Draws bounding boxes around detected stop signs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from skimage.feature import hog\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Load Data and Train Model (if not already trained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\ENVY\\Desktop\\CSE445\\CSE445.5-MSRb-Group-8\n",
      "Stop signs path: C:\\Users\\ENVY\\Desktop\\CSE445\\CSE445.5-MSRb-Group-8\\Data\n",
      "Non-stop signs path: C:\\Users\\ENVY\\Desktop\\CSE445\\CSE445.5-MSRb-Group-8\\Data2\n",
      "Loading stop sign images from: C:\\Users\\ENVY\\Desktop\\CSE445\\CSE445.5-MSRb-Group-8\\Data\n",
      "Loaded 50 stop sign images\n",
      "Loading non-stop sign images from: C:\\Users\\ENVY\\Desktop\\CSE445\\CSE445.5-MSRb-Group-8\\Data2\n",
      "Loaded 35 non-stop sign images\n",
      "\n",
      "Total images loaded: 85\n",
      "Stop signs: 50, Non-stop signs: 35\n"
     ]
    }
   ],
   "source": [
    "# Define image size for training\n",
    "size = (128, 128)\n",
    "\n",
    "# Dynamic paths that work regardless of where the project is located\n",
    "# Get project root directory - works from any location\n",
    "current_dir = os.path.abspath(os.getcwd())\n",
    "project_root = current_dir\n",
    "\n",
    "# Look for project root by finding the Data folder\n",
    "# Go up directories until we find Data folder or reach filesystem root\n",
    "max_levels = 5  # Prevent infinite loops\n",
    "for _ in range(max_levels):\n",
    "    if os.path.exists(os.path.join(project_root, \"Data\")) and os.path.exists(os.path.join(project_root, \"Data2\")):\n",
    "        break\n",
    "    parent = os.path.dirname(project_root)\n",
    "    if parent == project_root:  # Reached filesystem root\n",
    "        break\n",
    "    project_root = parent\n",
    "\n",
    "# Build paths relative to project root\n",
    "path_stop = os.path.join(project_root, \"Data\")  # Stop signs folder\n",
    "path_non_stop = os.path.join(project_root, \"Data2\")  # Non-stop signs folder\n",
    "\n",
    "# Print paths for debugging\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Stop signs path: {path_stop}\")\n",
    "print(f\"Non-stop signs path: {path_non_stop}\")\n",
    "\n",
    "# Lists to store images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Process stop sign images (label 1)\n",
    "if not os.path.exists(path_stop):\n",
    "    print(f\"Error: Stop signs folder not found at: {path_stop}\")\n",
    "else:\n",
    "    print(f\"Loading stop sign images from: {path_stop}\")\n",
    "    for file_name in os.listdir(path_stop):\n",
    "        if file_name.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "            img_path = os.path.join(path_stop, file_name)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, size)  # Resize to defined size\n",
    "                images.append(img)\n",
    "                labels.append(1)  # Label for stop signs\n",
    "    print(f\"Loaded {sum(labels)} stop sign images\")\n",
    "\n",
    "# Process non-stop sign images (label 0)\n",
    "if not os.path.exists(path_non_stop):\n",
    "    print(f\"Error: Non-stop signs folder not found at: {path_non_stop}\")\n",
    "else:\n",
    "    print(f\"Loading non-stop sign images from: {path_non_stop}\")\n",
    "    non_stop_count = 0\n",
    "    for file_name in os.listdir(path_non_stop):\n",
    "        if file_name.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "            img_path = os.path.join(path_non_stop, file_name)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, size)  # Resize to defined size\n",
    "                images.append(img)\n",
    "                labels.append(0)  # Label for non-stop signs\n",
    "                non_stop_count += 1\n",
    "    print(f\"Loaded {non_stop_count} non-stop sign images\")\n",
    "\n",
    "print(f\"\\nTotal images loaded: {len(images)}\")\n",
    "print(f\"Stop signs: {sum(labels)}, Non-stop signs: {len(labels) - sum(labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting HOG features...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m hog_features = []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     features, _ = hog(image, pixels_per_cell=(\u001b[32m9\u001b[39m, \u001b[32m9\u001b[39m), cells_per_block=(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m), \n\u001b[32m      6\u001b[39m                       orientations=\u001b[32m10\u001b[39m, block_norm=\u001b[33m'\u001b[39m\u001b[33mL2-Hys\u001b[39m\u001b[33m'\u001b[39m, visualize=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      7\u001b[39m     hog_features.append(features)\n\u001b[32m      9\u001b[39m X = np.array(hog_features)\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Extract HOG features from all images\n",
    "print(\"Extracting HOG features...\")\n",
    "hog_features = []\n",
    "for image in images:\n",
    "    features, _ = hog(image, pixels_per_cell=(9, 9), cells_per_block=(2, 2), \n",
    "                      orientations=10, block_norm='L2-Hys', visualize=False)\n",
    "    hog_features.append(features)\n",
    "\n",
    "X = np.array(hog_features)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(f\"HOG features shape: {X.shape}\")\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM model (or load if already trained)\n",
    "model_path = os.path.join(project_root, \"Support\", \"sliding_window_model.pkl\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Loading pre-trained model...\")\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    print(\"Model loaded successfully!\")\n",
    "else:\n",
    "    print(\"Training SVM model...\")\n",
    "    model = svm.SVC(kernel='linear', C=1.0, probability=True)  # probability=True for confidence scores\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Save the model\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(\"Model trained and saved!\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model accuracy on test set: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window Detection Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, window_size=(128, 128), step_size=32):\n",
    "    \"\"\"\n",
    "    Slide a window across the image.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image (grayscale)\n",
    "        window_size: Size of the sliding window (width, height)\n",
    "        step_size: Step size for sliding the window\n",
    "    \n",
    "    Yields:\n",
    "        (x, y, window): Coordinates and the window image\n",
    "    \"\"\"\n",
    "    for y in range(0, image.shape[0] - window_size[1] + 1, step_size):\n",
    "        for x in range(0, image.shape[1] - window_size[0] + 1, step_size):\n",
    "            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])\n",
    "\n",
    "\n",
    "def detect_stop_signs(image, model, window_size=(128, 128), step_size=32, \n",
    "                      scales=[1.0, 0.75, 0.5, 1.25, 1.5], threshold=0.5):\n",
    "    \"\"\"\n",
    "    Detect stop signs in an image using sliding window approach.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image (grayscale or color)\n",
    "        model: Trained classifier model\n",
    "        window_size: Base size of the sliding window\n",
    "        step_size: Step size for sliding\n",
    "        scales: List of scales to search at\n",
    "        threshold: Confidence threshold for detections\n",
    "    \n",
    "    Returns:\n",
    "        detections: List of (x, y, w, h, confidence) tuples\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "    \n",
    "    detections = []\n",
    "    \n",
    "    # Search at multiple scales\n",
    "    for scale in scales:\n",
    "        # Resize image\n",
    "        scaled_width = int(gray.shape[1] * scale)\n",
    "        scaled_height = int(gray.shape[0] * scale)\n",
    "        scaled_image = cv2.resize(gray, (scaled_width, scaled_height))\n",
    "        \n",
    "        # Adjust window size for this scale\n",
    "        scaled_window = (int(window_size[0] * scale), int(window_size[1] * scale))\n",
    "        scaled_step = int(step_size * scale)\n",
    "        \n",
    "        # Slide window across scaled image\n",
    "        for x, y, window in sliding_window(scaled_image, scaled_window, scaled_step):\n",
    "            # Resize window to model input size if needed\n",
    "            if window.shape != window_size[::-1]:  # window_size is (width, height), shape is (height, width)\n",
    "                window = cv2.resize(window, window_size)\n",
    "            \n",
    "            # Extract HOG features\n",
    "            try:\n",
    "                features, _ = hog(window, pixels_per_cell=(9, 9), cells_per_block=(2, 2), \n",
    "                                 orientations=10, block_norm='L2-Hys', visualize=False)\n",
    "                features = features.reshape(1, -1)\n",
    "                \n",
    "                # Predict\n",
    "                prediction = model.predict(features)[0]\n",
    "                confidence = model.predict_proba(features)[0][1]  # Probability of being stop sign\n",
    "                \n",
    "                # If detected as stop sign with sufficient confidence\n",
    "                if prediction == 1 and confidence >= threshold:\n",
    "                    # Scale coordinates back to original image size\n",
    "                    orig_x = int(x / scale)\n",
    "                    orig_y = int(y / scale)\n",
    "                    orig_w = int(scaled_window[0] / scale)\n",
    "                    orig_h = int(scaled_window[1] / scale)\n",
    "                    \n",
    "                    detections.append((orig_x, orig_y, orig_w, orig_h, confidence))\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    return detections\n",
    "\n",
    "\n",
    "def non_max_suppression(detections, overlap_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Apply non-maximum suppression to remove overlapping detections.\n",
    "    \n",
    "    Args:\n",
    "        detections: List of (x, y, w, h, confidence) tuples\n",
    "        overlap_threshold: IoU threshold for suppression\n",
    "    \n",
    "    Returns:\n",
    "        filtered_detections: List of filtered detections\n",
    "    \"\"\"\n",
    "    if len(detections) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Convert to numpy array for easier manipulation\n",
    "    boxes = np.array([[d[0], d[1], d[0] + d[2], d[1] + d[3]] for d in detections])\n",
    "    scores = np.array([d[4] for d in detections])\n",
    "    \n",
    "    # Sort by confidence (descending)\n",
    "    indices = np.argsort(scores)[::-1]\n",
    "    \n",
    "    keep = []\n",
    "    while len(indices) > 0:\n",
    "        # Keep the box with highest confidence\n",
    "        current = indices[0]\n",
    "        keep.append(current)\n",
    "        \n",
    "        if len(indices) == 1:\n",
    "            break\n",
    "        \n",
    "        # Calculate IoU with remaining boxes\n",
    "        current_box = boxes[current]\n",
    "        other_boxes = boxes[indices[1:]]\n",
    "        \n",
    "        # Calculate intersection\n",
    "        x1 = np.maximum(current_box[0], other_boxes[:, 0])\n",
    "        y1 = np.maximum(current_box[1], other_boxes[:, 1])\n",
    "        x2 = np.minimum(current_box[2], other_boxes[:, 2])\n",
    "        y2 = np.minimum(current_box[3], other_boxes[:, 3])\n",
    "        \n",
    "        intersection = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)\n",
    "        \n",
    "        # Calculate union\n",
    "        current_area = (current_box[2] - current_box[0]) * (current_box[3] - current_box[1])\n",
    "        other_areas = (other_boxes[:, 2] - other_boxes[:, 0]) * (other_boxes[:, 3] - other_boxes[:, 1])\n",
    "        union = current_area + other_areas - intersection\n",
    "        \n",
    "        # Calculate IoU\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # Remove boxes with high overlap\n",
    "        indices = indices[1:][iou < overlap_threshold]\n",
    "    \n",
    "    return [detections[i] for i in keep]\n",
    "\n",
    "\n",
    "def draw_detections(image, detections, color=(0, 255, 0), thickness=2):\n",
    "    \"\"\"\n",
    "    Draw bounding boxes on image.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image (can be color or grayscale)\n",
    "        detections: List of (x, y, w, h, confidence) tuples\n",
    "        color: Bounding box color (BGR format)\n",
    "        thickness: Line thickness\n",
    "    \n",
    "    Returns:\n",
    "        image_with_boxes: Image with drawn bounding boxes\n",
    "    \"\"\"\n",
    "    # Convert to color if grayscale\n",
    "    if len(image.shape) == 2:\n",
    "        image_with_boxes = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        image_with_boxes = image.copy()\n",
    "    \n",
    "    for x, y, w, h, confidence in detections:\n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(image_with_boxes, (x, y), (x + w, y + h), color, thickness)\n",
    "        \n",
    "        # Draw confidence score\n",
    "        label = f\"Stop: {confidence:.2f}\"\n",
    "        label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        cv2.rectangle(image_with_boxes, (x, y - label_size[1] - 5), \n",
    "                     (x + label_size[0], y), color, -1)\n",
    "        cv2.putText(image_with_boxes, label, (x, y - 5), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "    \n",
    "    return image_with_boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a few images from the stop signs folder\n",
    "test_images_path = path_stop\n",
    "test_files = [f for f in os.listdir(test_images_path) \n",
    "              if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))][:3]  # Test on first 3 images\n",
    "\n",
    "fig, axes = plt.subplots(len(test_files), 2, figsize=(15, 5 * len(test_files)))\n",
    "\n",
    "if len(test_files) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for idx, filename in enumerate(test_files):\n",
    "    img_path = os.path.join(test_images_path, filename)\n",
    "    image = cv2.imread(img_path)\n",
    "    \n",
    "    if image is None:\n",
    "        continue\n",
    "    \n",
    "    # Convert to grayscale for detection\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect stop signs\n",
    "    print(f\"\\nDetecting in {filename}...\")\n",
    "    detections = detect_stop_signs(gray, model, window_size=(128, 128), \n",
    "                                   step_size=32, scales=[1.0, 0.75, 0.5, 1.25], \n",
    "                                   threshold=0.6)\n",
    "    print(f\"Found {len(detections)} detections before NMS\")\n",
    "    \n",
    "    # Apply non-maximum suppression\n",
    "    filtered_detections = non_max_suppression(detections, overlap_threshold=0.3)\n",
    "    print(f\"Found {len(filtered_detections)} detections after NMS\")\n",
    "    \n",
    "    # Draw detections\n",
    "    result_image = draw_detections(image, filtered_detections)\n",
    "    \n",
    "    # Display original and result\n",
    "    axes[idx, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    axes[idx, 0].set_title(f\"Original: {filename}\")\n",
    "    axes[idx, 0].axis('off')\n",
    "    \n",
    "    axes[idx, 1].imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
    "    axes[idx, 1].set_title(f\"Detections: {len(filtered_detections)} found\")\n",
    "    axes[idx, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Non-Stop Sign Images (Should have no detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a few images from the non-stop signs folder\n",
    "test_images_path = path_non_stop\n",
    "test_files = [f for f in os.listdir(test_images_path) \n",
    "              if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))][:3]  # Test on first 3 images\n",
    "\n",
    "fig, axes = plt.subplots(len(test_files), 2, figsize=(15, 5 * len(test_files)))\n",
    "\n",
    "if len(test_files) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for idx, filename in enumerate(test_files):\n",
    "    img_path = os.path.join(test_images_path, filename)\n",
    "    image = cv2.imread(img_path)\n",
    "    \n",
    "    if image is None:\n",
    "        continue\n",
    "    \n",
    "    # Convert to grayscale for detection\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect stop signs\n",
    "    print(f\"\\nDetecting in {filename}...\")\n",
    "    detections = detect_stop_signs(gray, model, window_size=(128, 128), \n",
    "                                   step_size=32, scales=[1.0, 0.75, 0.5, 1.25], \n",
    "                                   threshold=0.6)\n",
    "    print(f\"Found {len(detections)} detections before NMS\")\n",
    "    \n",
    "    # Apply non-maximum suppression\n",
    "    filtered_detections = non_max_suppression(detections, overlap_threshold=0.3)\n",
    "    print(f\"Found {len(filtered_detections)} detections after NMS\")\n",
    "    \n",
    "    # Draw detections\n",
    "    result_image = draw_detections(image, filtered_detections)\n",
    "    \n",
    "    # Display original and result\n",
    "    axes[idx, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    axes[idx, 0].set_title(f\"Original: {filename}\")\n",
    "    axes[idx, 0].axis('off')\n",
    "    \n",
    "    axes[idx, 1].imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
    "    axes[idx, 1].set_title(f\"Detections: {len(filtered_detections)} found\")\n",
    "    axes[idx, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on Parameters\n",
    "\n",
    "- **window_size**: Size of the sliding window (should match training size: 128x128)\n",
    "- **step_size**: How many pixels to move the window each step (smaller = more detections but slower)\n",
    "- **scales**: Different scales to search at (1.0 = original size, 0.5 = half size, etc.)\n",
    "- **threshold**: Confidence threshold for detections (higher = fewer false positives)\n",
    "- **overlap_threshold**: IoU threshold for non-maximum suppression (higher = more overlapping boxes kept)\n",
    "\n",
    "### Tips for Better Detection:\n",
    "1. Adjust `threshold` to balance false positives vs false negatives\n",
    "2. Use more scales for better detection at different sizes\n",
    "3. Smaller `step_size` gives better coverage but is slower\n",
    "4. Adjust `overlap_threshold` based on how many overlapping detections you expect\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
